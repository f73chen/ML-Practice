# -*- coding: utf-8 -*-
"""grace_chen_bootcamp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qARxOvFIFBXRyIeIwfbRphMQXPbNrhyH
"""

# import keras packages and the CIFAR-10 dataset
import tensorflow as tf
import keras
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Conv2D, MaxPooling2D
from keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import matplotlib.pyplot as plt

# loads "a dataset of 50,000 32x32 color training images and 10,000 test images, labeled over 10 categories"
TRAIN_SIZE = 50000             # 50,000 images in training set
TEST_SIZE = 10000              # 10,000 images in test/validation set
IMG_ROWS, IMG_COLS = 32, 32    # each image is 32x32 pixels
NUM_CHANNELS = 3               # 3 channels for 3 colours RGB
NUM_CLASSES = 10               # 10 categories

BATCH_SIZE = 64                # learns from batches of 64 images instead of the full training set
EPOCHS = 10                    # number of iterations over the entire training set (accuracy_graph.png was based on 400 epochs)

(xTrain, yTrain), (xTest, yTest) = cifar10.load_data()    # load the dataset into train and test variables

# turn classes into one-hot encoding, e.g. [6] --> [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]
yTrain = keras.utils.to_categorical(yTrain, NUM_CLASSES)
yTest = keras.utils.to_categorical(yTest, NUM_CLASSES)

# normalize images by dividing by the max pixel value of 255
# else loss decreases but accuracy remains bad (~0.1)
xTrain = xTrain.astype('float32')/255.0
xTest = xTest.astype('float32')/255.0

# create a sequential model then add layers
model = Sequential()

# uses a modified 3-block VGG-style architecture (Conv2D, Conv2D, MaxPooling2D)
# Conv2D slides a 2D matrix "filter" over the image then performs element-wise multiplication. "same" padding means the output image is the same size as the original
# BatchNormalization is used to normalize image values (mean 0 and unit variance) so the network learns faster
# MaxPooling2D takes the maximum value within a window of size (2, 2)
# Dropout randomly sets the specified proportion of inputs to 0 to reduce overfitting the training data
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(IMG_ROWS, IMG_COLS, NUM_CHANNELS)))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.2))

# the depth of the model (number of Conv2D filters) is increased with each block
# Dropout rate is increased along the model so deeper layers regularize more than initial layers
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.3))

model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.4))

# Flatten converts a high-dimensional matrix to a single array, so the deep Conv2D layers can connect to the Dense layer
# Dense is a fully-connected layer, where each node from the last layer is connected to every node in the next
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

# the last layer is used to make predictions, so a softmax function returns the highest probability classification
model.add(Dense(10, activation='softmax'))

# Adam optimizer updates the learning rate so the model learns fast at first then fine-tunes near convergence
# opt = SGD(lr=0.001, momentum=0.9) also works well, and is what the included accuracy_graph.PNG is based off of
opt = Adam(learning_rate=0.01)
model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer=opt,
              metrics=['accuracy'])

# use a data generator to slightly change true training data so there are more examples to learn from
# encourages CNN to recognize general features
datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
itTrain = datagen.flow(xTrain, yTrain, batch_size=BATCH_SIZE)
steps = int(xTrain.shape[0]/64)

# generates a history of the model accuracy and loss as it iterates over the epochs
history = model.fit(itTrain,
          steps_per_epoch=steps,
          epochs=EPOCHS,
          verbose=1,
          validation_data=(xTest, yTest))

# prints the final loss and accuracy after training
score = model.evaluate(xTest, yTest, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

# use matplotlib to show training and validation accuracy over each epoch
# note that eventually, test/validation accuracy and loss stops improving even when training loss decreases
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# use matplotlib to show test and validation loss over each epoch
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

# source: https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/
